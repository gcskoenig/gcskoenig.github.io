<!DOCTYPE html>
<html lang="en" dir="auto">

<head><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="index, follow">
<title>If interpretability is the answer, what is the question? | Gunnar König</title>
<meta name="keywords" content="first">
<meta name="description" content="I propose a taxonomy of the types of questions that IML methods can answer.">
<meta name="author" content="Me">
<link rel="canonical" href="https://gunnarkoenig.com/posts/2022/blub/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.min.48a18943c2fc15c38a372b8dde1f5e5dc0bc64fa6cb90f5a817d2f8c76b7f3ae.css" integrity="sha256-SKGJQ8L8FcOKNyuN3h9eXcC8ZPpsuQ9agX0vjHa3864=" rel="preload stylesheet" as="style">
<script defer crossorigin="anonymous" src="/assets/js/highlight.min.2840b7fccd34145847db71a290569594bdbdb00047097f75d6495d162f5d7dff.js" integrity="sha256-KEC3/M00FFhH23GikFaVlL29sABHCX911kldFi9dff8="
    onload="hljs.initHighlightingOnLoad();"></script>
<link rel="icon" href="https://gunnarkoenig.com/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="https://gunnarkoenig.com/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://gunnarkoenig.com/favicon-32x32.png">
<link rel="apple-touch-icon" href="https://gunnarkoenig.com/apple-touch-icon.png">
<link rel="mask-icon" href="https://gunnarkoenig.com/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
    <style>
        @media (prefers-color-scheme: dark) {
            :root {
                --theme: rgb(29, 30, 32);
                --entry: rgb(46, 46, 51);
                --primary: rgb(218, 218, 219);
                --secondary: rgb(155, 156, 157);
                --tertiary: rgb(65, 66, 68);
                --content: rgb(196, 196, 197);
                --hljs-bg: rgb(46, 46, 51);
                --code-bg: rgb(55, 56, 62);
                --border: rgb(51, 51, 51);
            }

            .list {
                background: var(--theme);
            }

            .list:not(.dark)::-webkit-scrollbar-track {
                background: 0 0;
            }

            .list:not(.dark)::-webkit-scrollbar-thumb {
                border-color: var(--theme);
            }
        }

    </style>
</noscript>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
onload="renderMathInElement(document.body, 
    {
              delimiters: [
                  {left: '$$', right: '$$', display: true},
                  {left: '\\[', right: '\\]', display: true},
                  {left: '$', right: '$', display: false},
                  {left: '\\(', right: '\\)', display: false}
              ]
          }
    );"></script>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
	(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
	m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
	})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
	ga('create', 'UA-141772906-1', 'auto');
	
	ga('send', 'pageview');
}
</script><meta property="og:title" content="If interpretability is the answer, what is the question?" />
<meta property="og:description" content="I propose a taxonomy of the types of questions that IML methods can answer." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://gunnarkoenig.com/posts/2022/blub/" /><meta property="article:section" content="posts" />
<meta property="article:published_time" content="2022-04-16T00:30:03&#43;00:00" />
<meta property="article:modified_time" content="2022-04-16T00:30:03&#43;00:00" />

<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="If interpretability is the answer, what is the question?"/>
<meta name="twitter:description" content="I propose a taxonomy of the types of questions that IML methods can answer."/>


<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [, 
    {
      "@type": "ListItem",
      "position":  2 ,
      "name": "Posts",
      "item": "https://gunnarkoenig.com/posts/"
    }, 
    {
      "@type": "ListItem",
      "position":  3 ,
      "name": "If interpretability is the answer, what is the question?",
      "item": "https://gunnarkoenig.com/posts/2022/blub/"
    }
  ]
}
</script>
<script type="application/ld+json">
{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "If interpretability is the answer, what is the question?",
  "name": "If interpretability is the answer, what is the question?",
  "description": "I propose a taxonomy of the types of questions that IML methods can answer.",
  "keywords": [
    "first"
  ],
  "articleBody": "Introduction Focus\n model-agnostic post-hoc interpretability supervised learning scenarios tabular data  Background and Notation  target variable $Y$, covariates $Y$, model $\\hat{f}$, prediction $\\hat{Y}$ conditional (in)dependence $X \\not \\perp Y | Z$, probability distribution $P(X)$, event probability $p(x)$ do operator, graphical models structural causal models  Exemplary Use Cases Example 1 Scientific model, trust in model, goal is knowledge generation\nExample 2 Decision model, trust in prior knowledge, goal is debugging\nDimensions of Model-Agnostic Post-Hoc Interpretability Figure with all elements, i.e. data-level variables, model-level variables, target, prediction, performance. causal relationship $\\hat{Y} \\rightarrow$ data level?\nWhat do we aim to understand? underlying target: May also be referred to as label. In our example, xy. Real world object/entity. The quantity that the model tries to predict. Understanding it is the main inquiry for scientific applications.\nprediction: The model’s estimate of $Y$. In our example, xy. Can be seen as losgelöstes object with its own causal mechanism. Understanding it in order to understand the target must be differentiated from understanding it for its own sake, i.e. for debugging.\ntheir relationship (model performance): in order to understand how the model is able to estimate the prediction target. potentially provides both insight into prediction and underlying data. however, always provides a filtered perspective of the data via the model and vice versa. in general, interesting for purposes like variable selection.\nOn what level do we aim to understand? association: preserves dependence structure in the data. model is only evaluated where it was trained. for bayes error models aspect of the conditional distribution. Formally: effect scanning through the observational distribution\ncausal data-level: preserves causal relationships, breaks some dependencies. understand how the model behaves w.r.t. to acting in the real world.\ncausal model-level: only preserves the model’s mechanism, but does not repsect causal or dependence structure in the data. regards model as separate entity detached from the world. easy to simulate the effect of these interventions on the prediction.\nPotential extension: Which aspect do we aim to understand? E.g. main effect, average effect, global, local, interactions, etc. Quickly explain them an that typically distinguished along that axis\nClassification of Common IML Techniques Overview table with the 9 categories.\n    prediction target performance     association M-Plotconditional SHAP - conditional SAGECFIASV   causal (data-level) CRCSVs MCRHastie PDP Invariant prediction importance   causal (model-level) CXplainmarginal SHAP - PFImarginal SAGE    Mixed Categories E.g. dedact is a combination or Causal shapley values paper (direct and indirect)\nRelationships between categories In principle mutually exclusive. Demonstrate on examples in one figure (e.g. respective global relevance plot for each type in a 3x3 grid), proof in appendix.\napproach 1: assumptions and their consequences\n statistical independence of covariates causal independence of covariates observational identifiability of causal effect? bayes optimal predictor perfect predictor  approach 2: for each of the 9 classes, list which other classes implay the class and under which assumption they do so\ne.g.: causal model-level prediction given …, associative causal data-level prediction given\nUse Cases and Application Use Case 1 Use Case 2 Discussion consequences for development of iml: not suitable for many questions?\n why interpret the data through a model? when is refitting more important  consequences for interpretation: many methods are applied incorrectly?\nLimitations The taxonomy is not comprehensive. I.e. distinguish local/global, also does not include methods not fitting the focus (non tabular, model specific, surrogate models)\nRelated Work interpreting the model vs interpreting the data paper janzing feature relevance quantification\nConclusion bli bla blub\n",
  "wordCount" : "565",
  "inLanguage": "en",
  "datePublished": "2022-04-16T00:30:03Z",
  "dateModified": "2022-04-16T00:30:03Z",
  "author":{
    "@type": "Person",
    "name": "Me"
  },
  "mainEntityOfPage": {
    "@type": "WebPage",
    "@id": "https://gunnarkoenig.com/posts/2022/blub/"
  },
  "publisher": {
    "@type": "Organization",
    "name": "Gunnar König",
    "logo": {
      "@type": "ImageObject",
      "url": "https://gunnarkoenig.com/favicon.ico"
    }
  }
}
</script>
</head>

<body class="" id="top">
<script>
    if (localStorage.getItem("pref-theme") === "dark") {
        document.body.classList.add('dark');
    } else if (localStorage.getItem("pref-theme") === "light") {
        document.body.classList.remove('dark')
    } else if (window.matchMedia('(prefers-color-scheme: dark)').matches) {
        document.body.classList.add('dark');
    }

</script>

<header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="https://gunnarkoenig.com" accesskey="h" title="Gunnar König (Alt + H)">Gunnar König</a>
            <span class="logo-switches">
                <button id="theme-toggle" accesskey="t" title="(Alt + T)">
                    <svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <path d="M21 12.79A9 9 0 1 1 11.21 3 7 7 0 0 0 21 12.79z"></path>
                    </svg>
                    <svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24"
                        fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"
                        stroke-linejoin="round">
                        <circle cx="12" cy="12" r="5"></circle>
                        <line x1="12" y1="1" x2="12" y2="3"></line>
                        <line x1="12" y1="21" x2="12" y2="23"></line>
                        <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
                        <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
                        <line x1="1" y1="12" x2="3" y2="12"></line>
                        <line x1="21" y1="12" x2="23" y2="12"></line>
                        <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
                        <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
                    </svg>
                </button>
            </span>
        </div>
        <ul id="menu">
            <li>
                <a href="https://gunnarkoenig.com/aboutme/" title="about">
                    <span>about</span>
                </a>
            </li>
            <li>
                <a href="https://gunnarkoenig.com/publications/" title="publications">
                    <span>publications</span>
                </a>
            </li>
            <li>
                <a href="https://gunnarkoenig.com/teaching/" title="teaching">
                    <span>teaching</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    <div class="breadcrumbs"><a href="https://gunnarkoenig.com">Home</a>&nbsp;»&nbsp;<a href="https://gunnarkoenig.com/posts/">Posts</a></div>
    <h1 class="post-title">
      If interpretability is the answer, what is the question?
    </h1>
    <div class="post-description">
      I propose a taxonomy of the types of questions that IML methods can answer.
    </div>
    <div class="post-meta"><span title='2022-04-16 00:30:03 +0000 +0000'>April 16, 2022</span>&nbsp;·&nbsp;3 min&nbsp;·&nbsp;Me

</div>
  </header> <div class="toc">
    <details >
        <summary accesskey="c" title="(Alt + C)">
            <span class="details">Table of Contents</span>
        </summary>

        <div class="inner"><ul>
                <li>
                    <a href="#introduction" aria-label="Introduction">Introduction</a></li>
                <li>
                    <a href="#background-and-notation" aria-label="Background and Notation">Background and Notation</a></li>
                <li>
                    <a href="#exemplary-use-cases" aria-label="Exemplary Use Cases">Exemplary Use Cases</a><ul>
                        
                <li>
                    <a href="#example-1" aria-label="Example 1">Example 1</a></li>
                <li>
                    <a href="#example-2" aria-label="Example 2">Example 2</a></li></ul>
                </li>
                <li>
                    <a href="#dimensions-of-model-agnostic-post-hoc-interpretability" aria-label="Dimensions of Model-Agnostic Post-Hoc Interpretability">Dimensions of Model-Agnostic Post-Hoc Interpretability</a><ul>
                        
                <li>
                    <a href="#what-do-we-aim-to-understand" aria-label="What do we aim to understand?">What do we aim to understand?</a></li>
                <li>
                    <a href="#on-what-level-do-we-aim-to-understand" aria-label="On what level do we aim to understand?">On what level do we aim to understand?</a></li>
                <li>
                    <a href="#potential-extension-which-aspect-do-we-aim-to-understand" aria-label="Potential extension: Which aspect do we aim to understand?">Potential extension: Which aspect do we aim to understand?</a></li>
                <li>
                    <a href="#classification-of-common-iml-techniques" aria-label="Classification of Common IML Techniques">Classification of Common IML Techniques</a></li>
                <li>
                    <a href="#mixed-categories" aria-label="Mixed Categories">Mixed Categories</a></li></ul>
                </li>
                <li>
                    <a href="#relationships-between-categories" aria-label="Relationships between categories">Relationships between categories</a></li>
                <li>
                    <a href="#use-cases-and-application" aria-label="Use Cases and Application">Use Cases and Application</a><ul>
                        
                <li>
                    <a href="#use-case-1" aria-label="Use Case 1">Use Case 1</a></li>
                <li>
                    <a href="#use-case-2" aria-label="Use Case 2">Use Case 2</a></li></ul>
                </li>
                <li>
                    <a href="#discussion" aria-label="Discussion">Discussion</a></li>
                <li>
                    <a href="#limitations" aria-label="Limitations">Limitations</a></li>
                <li>
                    <a href="#related-work" aria-label="Related Work">Related Work</a></li>
                <li>
                    <a href="#conclusion" aria-label="Conclusion">Conclusion</a>
                </li>
            </ul>
        </div>
    </details>
</div>

  <div class="post-content"><h1 id="introduction">Introduction<a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h1>
<p>Focus</p>
<ul>
<li>model-agnostic post-hoc interpretability</li>
<li>supervised learning scenarios</li>
<li>tabular data</li>
</ul>
<h1 id="background-and-notation">Background and Notation<a hidden class="anchor" aria-hidden="true" href="#background-and-notation">#</a></h1>
<ul>
<li>target variable $Y$, covariates $Y$, model $\hat{f}$, prediction $\hat{Y}$</li>
<li>conditional (in)dependence $X \not \perp Y | Z$, probability distribution $P(X)$, event probability $p(x)$</li>
<li>do operator, graphical models</li>
<li>structural causal models</li>
</ul>
<h1 id="exemplary-use-cases">Exemplary Use Cases<a hidden class="anchor" aria-hidden="true" href="#exemplary-use-cases">#</a></h1>
<h2 id="example-1">Example 1<a hidden class="anchor" aria-hidden="true" href="#example-1">#</a></h2>
<p>Scientific model, trust in model, goal is knowledge generation</p>
<h2 id="example-2">Example 2<a hidden class="anchor" aria-hidden="true" href="#example-2">#</a></h2>
<p>Decision model, trust in prior knowledge, goal is debugging</p>
<h1 id="dimensions-of-model-agnostic-post-hoc-interpretability">Dimensions of Model-Agnostic Post-Hoc Interpretability<a hidden class="anchor" aria-hidden="true" href="#dimensions-of-model-agnostic-post-hoc-interpretability">#</a></h1>
<p>Figure with all elements, i.e. data-level variables, model-level variables, target, prediction, performance. causal relationship $\hat{Y} \rightarrow$ data level?</p>
<h2 id="what-do-we-aim-to-understand">What do we aim to understand?<a hidden class="anchor" aria-hidden="true" href="#what-do-we-aim-to-understand">#</a></h2>
<p><strong>underlying target:</strong> May also be referred to as label. In our example, xy. Real world object/entity. The quantity that the model tries to predict. Understanding it is the main inquiry for scientific applications.</p>
<p><strong>prediction:</strong> The model&rsquo;s estimate of $Y$. In our example, xy. Can be seen as losgelöstes object with its own causal mechanism. Understanding it in order to understand the target must be differentiated from understanding it for its own sake, i.e. for debugging.</p>
<p><strong>their relationship (model performance):</strong> in order to understand how the model is able to estimate the prediction target. potentially provides both insight into prediction and underlying data. however, always provides a filtered perspective of the data via the model and vice versa. in general, interesting for purposes like variable selection.</p>
<h2 id="on-what-level-do-we-aim-to-understand">On what level do we aim to understand?<a hidden class="anchor" aria-hidden="true" href="#on-what-level-do-we-aim-to-understand">#</a></h2>
<p><strong>association:</strong> preserves dependence structure in the data. model is only evaluated where it was trained. for bayes error models aspect of the conditional distribution. Formally: effect scanning through the observational distribution</p>
<p><strong>causal data-level:</strong> preserves causal relationships, breaks some dependencies. understand how the model behaves w.r.t. to acting in the real world.</p>
<p><strong>causal model-level:</strong> only preserves the model&rsquo;s mechanism, but does not repsect causal or dependence structure in the data. regards model as separate entity detached from the world. easy to simulate the effect of these interventions on the prediction.</p>
<h2 id="potential-extension-which-aspect-do-we-aim-to-understand">Potential extension: Which aspect do we aim to understand?<a hidden class="anchor" aria-hidden="true" href="#potential-extension-which-aspect-do-we-aim-to-understand">#</a></h2>
<p>E.g. main effect, average effect, global, local, interactions, etc.
Quickly explain them an that typically distinguished along that axis</p>
<h2 id="classification-of-common-iml-techniques">Classification of Common IML Techniques<a hidden class="anchor" aria-hidden="true" href="#classification-of-common-iml-techniques">#</a></h2>
<p>Overview table with the 9 categories.</p>
<table>
<thead>
<tr>
<th></th>
<th>prediction</th>
<th>target</th>
<th>performance</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>association</strong></td>
<td>M-Plot<!-- raw HTML omitted -->conditional SHAP</td>
<td>-</td>
<td>conditional SAGE<!-- raw HTML omitted -->CFI<!-- raw HTML omitted -->ASV</td>
</tr>
<tr>
<td><strong>causal (data-level)</strong></td>
<td>CR<!-- raw HTML omitted -->CSVs</td>
<td>MCR<!-- raw HTML omitted -->Hastie PDP</td>
<td>Invariant prediction importance</td>
</tr>
<tr>
<td><strong>causal (model-level)</strong></td>
<td>CXplain<!-- raw HTML omitted -->marginal SHAP</td>
<td>-</td>
<td>PFI<!-- raw HTML omitted -->marginal SAGE</td>
</tr>
</tbody>
</table>
<h2 id="mixed-categories">Mixed Categories<a hidden class="anchor" aria-hidden="true" href="#mixed-categories">#</a></h2>
<p>E.g. dedact is a combination
or Causal shapley values paper (direct and indirect)</p>
<h1 id="relationships-between-categories">Relationships between categories<a hidden class="anchor" aria-hidden="true" href="#relationships-between-categories">#</a></h1>
<p>In principle mutually exclusive.
Demonstrate on examples in one figure (e.g. respective global relevance plot for each type in a 3x3 grid), proof in appendix.</p>
<p><strong>approach 1:</strong> assumptions and their consequences</p>
<ul>
<li>statistical independence of covariates</li>
<li>causal independence of covariates</li>
<li>observational identifiability of causal effect?</li>
<li>bayes optimal predictor</li>
<li>perfect predictor</li>
</ul>
<p><strong>approach 2:</strong> for each of the 9 classes, list which other classes implay the class and under which assumption they do so</p>
<p>e.g.: causal model-level prediction given &hellip;, associative causal data-level prediction given</p>
<h1 id="use-cases-and-application">Use Cases and Application<a hidden class="anchor" aria-hidden="true" href="#use-cases-and-application">#</a></h1>
<h2 id="use-case-1">Use Case 1<a hidden class="anchor" aria-hidden="true" href="#use-case-1">#</a></h2>
<h2 id="use-case-2">Use Case 2<a hidden class="anchor" aria-hidden="true" href="#use-case-2">#</a></h2>
<h1 id="discussion">Discussion<a hidden class="anchor" aria-hidden="true" href="#discussion">#</a></h1>
<p>consequences for development of iml: not suitable for many questions?</p>
<ul>
<li>why interpret the data through a model?</li>
<li>when is refitting more important</li>
</ul>
<p>consequences for interpretation: many methods are applied incorrectly?</p>
<h1 id="limitations">Limitations<a hidden class="anchor" aria-hidden="true" href="#limitations">#</a></h1>
<p>The taxonomy is not comprehensive. I.e. distinguish local/global, also does not include methods not fitting the focus (non tabular, model specific, surrogate models)</p>
<h1 id="related-work">Related Work<a hidden class="anchor" aria-hidden="true" href="#related-work">#</a></h1>
<p>interpreting the model vs interpreting the data paper
janzing feature relevance quantification</p>
<h1 id="conclusion">Conclusion<a hidden class="anchor" aria-hidden="true" href="#conclusion">#</a></h1>
<p>bli bla blub</p>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
      <li><a href="https://gunnarkoenig.com/tags/first/">first</a></li>
    </ul>
<nav class="paginav">
  <a class="prev" href="https://gunnarkoenig.com/posts/2022/maths/">
    <span class="title">« Prev Page</span>
    <br>
    <span>Math typesetting tests</span>
  </a>
</nav>

  </footer>
</article>
    </main>
    
<footer class="footer">
    <span>&copy; 2022 <a href="https://gunnarkoenig.com">Gunnar König</a></span>
    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://git.io/hugopapermod" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu')
    if (menu) {
        menu.scrollLeft = localStorage.getItem("menu-scroll-position");
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
<script>
    document.getElementById("theme-toggle").addEventListener("click", () => {
        if (document.body.className.includes("dark")) {
            document.body.classList.remove('dark');
            localStorage.setItem("pref-theme", 'light');
        } else {
            document.body.classList.add('dark');
            localStorage.setItem("pref-theme", 'dark');
        }
    })

</script>
</body>

</html>
