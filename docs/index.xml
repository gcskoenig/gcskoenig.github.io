<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>Gunnar König</title>
    <link>https://gunnarkoenig.com/</link>
    <description>Recent content on Gunnar König</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Feb 2023 00:30:03 +0000</lastBuildDate><atom:link href="https://gunnarkoenig.com/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Improvement-Focused Causal Recourse (ICR)</title>
      <link>https://gunnarkoenig.com/posts/2023/icr-qr/</link>
      <pubDate>Wed, 08 Feb 2023 00:30:03 +0000</pubDate>
      
      <guid>https://gunnarkoenig.com/posts/2023/icr-qr/</guid>
      <description>Links for our AAAI paper on improvement-focused recourse.</description>
    </item>
    
    <item>
      <title>If interpretability is the answer, what is the question?</title>
      <link>https://gunnarkoenig.com/posts/2022/interpretability-levels/</link>
      <pubDate>Sat, 16 Apr 2022 00:30:03 +0000</pubDate>
      
      <guid>https://gunnarkoenig.com/posts/2022/interpretability-levels/</guid>
      <description>I propose a taxonomy of the types of questions that IML methods can answer.</description>
    </item>
    
    <item>
      <title>Hi! I&#39;m Gunnar.</title>
      <link>https://gunnarkoenig.com/aboutme/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gunnarkoenig.com/aboutme/</guid>
      <description>I am interested in the development of sustainable machine learning and its application for the societal good. So far, my research is focused on a causal perspective on explainability.
I am a postdoc with Ulrike Luxburg at the University of Tübingen. Before that, I did my PhD with Moritz Grosse-Wentrup and Bernd Bischl at LMU Munich and Unversity of Vienna. I&amp;rsquo;m a founding member of ThinkTech (prev. ConsciousCoders), helped start WeRePack and contributed to initiatives like data science for social good.</description>
    </item>
    
    <item>
      <title>Research</title>
      <link>https://gunnarkoenig.com/research/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gunnarkoenig.com/research/</guid>
      <description>I am broadly interested in trustworthy ML, currently with a focus on explainability and causality.
In my view, the field of explainability faces two fundamental challenges: First, explainability in itself is not a well-defined goal but rather conflates different incompatible subgoals. To make progress, the different subgoals must be disentangled. Second, explainability methods themselves are subject to interpretation, and their meaning is often misunderstood.
Throughout my PhD, we demonstrated that a causal perspective helps tackle these challenges.</description>
    </item>
    
    <item>
      <title>Teaching and Supervision</title>
      <link>https://gunnarkoenig.com/teaching/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://gunnarkoenig.com/teaching/</guid>
      <description>Teaching WS22: Multivariate Statistics
SS22: Advanced Machine Learning [course]
SS22: Seminar Introduction to Causal Inference [course]
WS21: Seminar Philosophy and Explainable AI, jointly at MCMP and Statistics Departement, [course]
SS21: Seminar Causality and Graphical Models, LMU Munich, [course]
SS21: Current Research in Data Science, LMU Munich
WS20: Seminar Ethics in AI, LMU Munich, [course]
WS20: Seminar: Current Research and Applications in Interpretable Machine Learning, LMU Munich, [course]
SS20: Seminar Causality and Graphical Models, LMU Munich, [course]</description>
    </item>
    
  </channel>
</rss>
